\documentclass[11pt]{article}
\usepackage{deauthor}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{enumitem}
\usepackage{sidecap}
\usepackage{framed}
\usepackage{cprotect}
\usepackage{enumitem}
\usepackage{listings}
\usepackage{amstext}
\usepackage{amstext}
\usepackage{pdfpages}
\usepackage{alltt}
\usepackage{epstopdf}
\usepackage{xspace,colortbl}
\usepackage[USenglish]{babel}
\usepackage{multirow}
\usepackage{url}
\usepackage{subfigure}
\usepackage{graphicx}%%
\usepackage{amssymb}
\usepackage{fmtcount}
\usepackage{amsfonts}
\usepackage{xspace}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage[mathscr]{eucal}
%\usepackage{psfrag}
\usepackage{colortbl}

\usepackage{bm}
\usepackage{times}
\usepackage[nospace]{cite}
\usepackage{csquotes}
\usepackage{enumitem}
\usepackage{geometry}
%\geometry{verbose,tmargin=2.54cm,bmargin=2.54cm,lmargin=2.54cm,rmargin=2.54cm}
\usepackage{babel}
\begin{document}

%\newtheorem{theorem}{Theorem}
%\newtheorem{example}{Example}
%\newtheorem{definition}{Definition}
%\newtheorem{problem}{Problem}
%\newtheorem{property}{Property}
%\newtheorem{proposition}{Proposition}
%\newtheorem{lemma}{Lemma}
%\newtheorem{corollary}{Corollary}

\newcommand{\cond}{\textrm{pred}\xspace}
\newcommand{\dataset}{data set\xspace}
\newcommand{\datasets}{data sets\xspace}
\newcommand{\spview}{\textsf{SPView}\xspace}
\newcommand{\fjview}{\textsf{FJView}\xspace}
\newcommand{\aggview}{\textsf{AggView}\xspace}
\newcommand{\hashfunc}[1]{\textsf{hash}(#1)\xspace}
\newcommand{\hashop}{\textsf{hash}\xspace}
\newcommand{\nsc}{\textsf{NormalizedSC}\xspace}
\newcommand{\rsc}{\textsf{RawSC}\xspace}

\newcommand{\avgfunc}{\ensuremath{\texttt{avg} }\xspace}
\newcommand{\maxfunc}{\ensuremath{\texttt{max} }\xspace}
\newcommand{\minfunc}{\ensuremath{\texttt{min} }\xspace}
\newcommand{\histfunc}{\ensuremath{\texttt{histogram\_numeric} }\xspace}
\newcommand{\countfunc}{\ensuremath{\texttt{count}}\xspace}
\newcommand{\sumfunc}{\ensuremath{\texttt{sum} }\xspace}
\newcommand{\varfunc}{\ensuremath{\texttt{var} }\xspace}
\newcommand{\stdfunc}{\ensuremath{\texttt{std} }\xspace}
\newcommand{\covfunc}{\ensuremath{\texttt{cov} }\xspace}
\newcommand{\corrfunc}{\ensuremath{\texttt{corr} }\xspace}
\newcommand{\medfunc}{\ensuremath{\texttt{median} }\xspace}
\newcommand{\percfunc}{\ensuremath{\texttt{percentile} }\xspace}
\newcommand{\havingfunc}{\ensuremath{\texttt{HAVING} }\xspace}
\newcommand{\selectfunc}{\ensuremath{\texttt{select} }\xspace}
\newcommand{\ratio}{\ensuremath{\rho }\xspace}
\newcommand{\mean}{\ensuremath{\texttt{mean} }\xspace}
\newcommand{\pred}{\ensuremath{\texttt{pred} }\xspace}

\newcommand{\insertion}{\ensuremath{\texttt{INSERT} }\xspace}
\newcommand{\update}{\ensuremath{\texttt{UPDATE} }\xspace}
\newcommand{\delete}{\ensuremath{\texttt{DELETE} }\xspace}
\newcommand{\svc}{View Cleaning\xspace}

\newcommand{\saqpfunc}{\ensuremath{\phi }\xspace}
\newcommand{\saqpplusfunc}{\ensuremath{\phi_{\clean} }\xspace}
\newcommand{\clean}{\ensuremath{\texttt{clean} }\xspace}
\newcommand{\sampleclean}{SampleClean\xspace}

\newcommand{\Correct}[1]{\texttt{Correct}\ensuremath(#1)\xspace}
\newcommand{\Remove}[2]{\texttt{Remove}\ensuremath(#1, #2)\xspace}
\newcommand{\Predicate}[1]{\texttt{Predicate}($#1$)\xspace}
\newcommand{\Predicaten}[1]{\texttt{Predicate}(#1)\xspace}
\newcommand{\Predicatec}[1]{\texttt{Predicate}(\texttt{Correct}($#1$))\xspace}
\newcommand{\Dedup}[2]{\texttt{Numdup}\ensuremath(#1)\xspace}

\newcommand{\jn}[1]{\textcolor{red}{\{\{JN: #1\}\}}\xspace}

\def\ojoin{\setbox0=\hbox{$\bowtie$}% 
  \rule[-.02ex]{.25em}{.4pt}\llap{\rule[\ht0]{.25em}{.4pt}}}
\def\leftouterjoin{\mathbin{\ojoin\mkern-5.8mu\bowtie}}
\def\rightouterjoin{\mathbin{\bowtie\mkern-5.8mu\ojoin}}
\def\fullouterjoin{\mathbin{\ojoin\mkern-5.8mu\bowtie\mkern-5.8mu\ojoin}}

\setlength{\belowdisplayskip}{1pt} \setlength{\belowdisplayshortskip}{1pt}
\setlength{\abovedisplayskip}{1pt} \setlength{\abovedisplayshortskip}{1pt}

\author{ Sanjay Krishnan$^1$, Jiannan Wang$^1$, Michael J. Franklin$^1$, Ken Goldberg$^1$,\\
Tim Kraska$^2$, Tova Milo$^3$, Eugene Wu$^4$\\ \\
$^1$UC Berkeley,~~$^2$Brown University,~~$^3$Tel Aviv University,~~$^4$Columnia University \\
%\{jnwang, sanjaykrishnan, franklin, goldberg\}@berkeley.edu\\
%milo@cs.tau.ac.il,tim\_kraska@brown.edu,ewu@columbia.edu
}

\title{SampleClean: Fast and Reliable Analytics on Dirty Data}
\maketitle
\begin{abstract}
An increasingly important challenge in data analytics is dirty data in the form of missing, duplicate, incorrect, or inconsistent values.  
In the SampleClean project, we have developed a new suite of algorithms to estimate the results of different types of analytic queries after applying data cleaning only to a sample.
First, This article describes methods for computing statistically bounded estimates of SUM, COUNT, and AVG queries from samples of data corrupted with duplications and incorrect values.
Some types of data error, such as duplication, can affect sampling probabilities so results have to be re-weighted to compensate for biases.
Then it presents an application of these query processing and data cleaning methods to materialized views maintenance.
The view cleaning algorithm applies hashing to efficiently maintain a uniform sample of rows in a materialized view, and then dirty data query processing techniques to correct stale query results.
Finally, the article describes a gradient-descent algorithm that extends this idea to the increasingly common Machine Learning-based analytics.
\end{abstract}

\input{intro.tex}
\input{background.tex}
\input{sampleclean.tex}
\input{viewcleaning.tex}
\input{activeclean.tex}
\input{relatedwork.tex}
\input{futurework.tex}
\input{conclusion.tex}


\fontsize{8.2pt}{8.4pt} \selectfont
\bibliographystyle{abbrv}
\bibliography{ref} 

\end{document}

